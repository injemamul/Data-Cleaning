{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Here’s a road map of what we will do with Pandas:"},{"metadata":{},"cell_type":"markdown","source":"1. Set up the environment and load the data\n2. Investigate the data\n3. Parse the different data tabs\n4. Standardize existing columns and create new ones\n5. Clean up the data using “apply” and “lambda” functions\n3. Reshape the data from wide to long by pivoting on multi-level indices and stacking\n3. Save the final results back to excel\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 1. Set up the environment and load the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the raw data using the ExcelFile object\ndata = pd.ExcelFile('/kaggle/input/reshaping-data/reshaping_data.xlsx')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Investigate the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, see the sheetnames available\ndata.sheet_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a peek at the first 10 rows of the first tab\ndata.parse(sheetname='ABC_inc', skiprows=0).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tabnames = data.sheet_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\ndf = data.parse(sheetname=tabnames[i], skiprows=7)\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Standardize existing columns and create new ones"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a list of the header row and strip up to the 4th letter. This is the location and year information\ncols1 = list(df.columns)\ncols1 = [str(x)[:4] for x in cols1]\n\n# make another list of the first row,this is the age group information\n# we need to preserve this information in the column name when we reshape the data \ncols2 = list(df.iloc[0,:])\ncols2 = [str(x) for x in cols2]\n\n# now join the two lists to make a combined column name which preserves our location, year and age-group information\ncols = [x+\"_\"+y for x,y in zip(cols1,cols2)]\n\n# Assign new column names to the dataframe\ndf.columns = cols\ndf.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop empty columns, Rename the useful columns\n# Note when you drop, you should specify axis=1 for columns and axis=0 for rows\ndf = df.drop([\"Unna_nan\"], axis=1).iloc[1:,:].rename(columns={'dist_nan':'district', 'prov_nan': 'province', 'part_nan':'partner', 'fund_nan':'financing_source'})\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer a new column for the organization, grab this name from the excel tab name\n# This should read 'ABC inc' if executed correctly\ndf['main_organization'] = tabnames[i].split(\"_\")[0] + \" \"+ tabnames[i].split(\"_\")[1]\ndf.main_organization.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let’s pause and look at the structure of our dataframe so far.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Clean up the data using “apply” and “lambda” functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make lists of the columns which need attention and use this as reference to execute\n# You will notice that I use list comprehension every time I generate an iterable like a list or dictionary\n# This is really amazing python functionality and I never want to go back to the old looping way of doing this!\nto_remove = [c for c in df.columns if \"Total\" in c] # redundant\nto_change = [c for c in df.columns if \"yrs\" in c] # numeric\n\n# drop unwanted columns\n# Notice that you need to specify inplace, otherwise pandas will return the data frame instead of changing it in place\ndf.drop(to_remove, axis=1, inplace= True) \n\n# Change the target column data types\nfor c in to_change:\n    df[c] = df[c].apply(lambda x: pd.to_numeric(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Reshape the data from wide to long by pivoting on multi-level indices and stacking"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, select the columns to use for a multi-level index. This depends on your data\n# Generally, you want all the identifier columns to be included in the multi-index \n# For this dataset, this is every non-numeric column\nidx =['district', 'province', 'partner', 'financing_source', 'main_organization']\n\n# Then pivot the dataset based on this multi-level index \nmulti_indexed_df = df.set_index(idx)\nmulti_indexed_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stack the columns to achieve the baseline long format for the data\nstacked_df = multi_indexed_df.stack(dropna=False)\nstacked_df.head(25) \n\n# check out the results!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mind. Blown! Exactly how I felt when I saw this for the first time too.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now do a reset to disband the multi-level index, we only needed it to pivot our data during the reshape\nlong_df = stacked_df.reset_index()\nlong_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make series of lists which split year from target age-group\n# the .str attribute is how you manipulate the data frame objects and columns with strings in them\ncol_str = long_df.level_5.str.split(\"_\") \ncol_str.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# engineer the columns we want, one columns takes the first item in col_str and another columns takes the second \nlong_df['target_year'] = [x[0] for x in col_str] \nlong_df['target_age'] = [x[1] for x in col_str]\nlong_df['target_quantity'] = long_df[0] # rename this column\nlong_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the now redundant columns\ndf_final = long_df.drop(['level_5', 0], axis=1)\ndf_final.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Save the final results back to Excel"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.to_excel(\"reshaping_result_long_format.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}